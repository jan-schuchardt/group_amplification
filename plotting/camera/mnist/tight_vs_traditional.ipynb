{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import opacus\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from group_amplification.privacy_analysis.composition.pld.accounting import pld_tight_group, pld_traditional_group\n",
    "from group_amplification.privacy_analysis.base_mechanisms import GaussianMechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and the training and test steps\n",
    "# The model uses convolutional neural network layers\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "class LitMNIST(pl.LightningModule):\n",
    "    def __init__(self, base_model, optimizer):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.base_model(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.base_model(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        accuracy = (preds == y).float().mean()\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_accuracy', accuracy, prog_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for reading the data, training the model\n",
    "\n",
    "import opacus.data_loader\n",
    "import opacus.optimizers\n",
    "\n",
    "\n",
    "num_epochs = 8\n",
    "num_workers = 4\n",
    "batch_size_train = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])\n",
    "dataset = MNIST('/ceph/hdd/shared/schuchaj_MNIST', train=True, download=True, transform=transform)\n",
    "train_dataset, val_dataset = random_split(dataset, [55000, 5000])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_train, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1000, num_workers=num_workers)\n",
    "\n",
    "noise_multiplier = 0.6\n",
    "max_grad_norm = 0.0001\n",
    "subsampling_rate = batch_size_train / len(train_dataset)\n",
    "num_iterations = len(train_loader) * num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_tight = pld_tight_group(np.arange(11), GaussianMechanism(noise_multiplier), \n",
    "                         subsampling_rate, 0, 2, num_iterations,\n",
    "                         {'value_discretization_interval': 1e-2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_traditional = pld_traditional_group(np.arange(11), GaussianMechanism(noise_multiplier), \n",
    "                         subsampling_rate, 2, num_iterations,\n",
    "                         {'value_discretization_interval': 1e-2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations_tight = (deltas_tight[8] < 1e-5).sum()\n",
    "print(max_iterations_tight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations_traditional = (deltas_traditional[8] < 1e-5).sum()\n",
    "print(max_iterations_traditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "base_model = ConvNet()\n",
    "optimizer = torch.optim.Adam(base_model.parameters(), lr=1e-3)\n",
    "\n",
    "base_model = opacus.grad_sample.GradSampleModule(base_model)\n",
    "optimizer = opacus.optimizers.DPOptimizer(optimizer,\n",
    "                                          expected_batch_size=batch_size_train,\n",
    "                                          noise_multiplier=noise_multiplier,\n",
    "                                          max_grad_norm=max_grad_norm)\n",
    "train_loader = opacus.data_loader.DPDataLoader.from_data_loader(train_loader, distributed=False)\n",
    "\n",
    "\n",
    "model = LitMNIST(base_model, optimizer)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=num_epochs, max_steps=max_iterations_tight)\n",
    "trainer.validate(model, val_loader)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "base_model = ConvNet()\n",
    "optimizer = torch.optim.Adam(base_model.parameters(), lr=1e-3)\n",
    "\n",
    "base_model = opacus.grad_sample.GradSampleModule(base_model)\n",
    "optimizer = opacus.optimizers.DPOptimizer(optimizer,\n",
    "                                          expected_batch_size=batch_size_train,\n",
    "                                          noise_multiplier=noise_multiplier,\n",
    "                                          max_grad_norm=max_grad_norm)\n",
    "train_loader = opacus.data_loader.DPDataLoader.from_data_loader(train_loader, distributed=False)\n",
    "\n",
    "model = LitMNIST(base_model, optimizer)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=num_epochs, max_steps=max_iterations_traditional)\n",
    "trainer.validate(model, val_loader)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/ceph/hdd/staff/schuchaj/group_amplification_plots/neurips24/mnist/half_page'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the losses over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy pasted from metrics.csv in lightning_logs N-1 and N, where N is most recent one\n",
    "\n",
    "accs_tight = [0.09040000289678574,\n",
    "              0.8776000142097473,\n",
    "              0.8948000073432922,\n",
    "              0.9020000100135803,\n",
    "              0.9047999978065491,\n",
    "              0.9010000824928284,\n",
    "              0.9067999720573425,\n",
    "              0.9104000926017761,\n",
    "              0.9121999740600586]\n",
    "\n",
    "accs_traditional = [0.09040000289678574]\n",
    "accs_traditional += 8 * [0.7963999509811401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "pal = sns.color_palette('colorblind', 2)\n",
    "\n",
    "ax.plot(accs_traditional, marker='x', c=pal[0], label='Post-hoc', linestyle='dashed')\n",
    "ax.plot(accs_tight, marker='x', c=pal[1], label='Specific')\n",
    "\n",
    "ax.set_ylabel('Val. accuracy', fontsize=9)\n",
    "ax.set_xlabel('Epoch', fontsize=9)\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot privacy over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "pal = sns.color_palette('colorblind', 2)\n",
    "\n",
    "ax.plot(deltas_traditional[8], c=pal[0], label='Post-hoc', linestyle='dashed')\n",
    "ax.plot(deltas_tight[8],  c=pal[1], label='Specific')\n",
    "ax.plot(np.ones_like(deltas_tight[8]) * 1e-5,\n",
    "         color='black',\n",
    "         linestyle='dotted',\n",
    "         label='Budget')\n",
    "\n",
    "ax.plot()\n",
    "\n",
    "ax.set_ylabel('ADP $\\delta(\\\\varepsilon=8)$', fontsize=9)\n",
    "ax.set_xlabel('Iteration t', fontsize=9)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group_amplification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
