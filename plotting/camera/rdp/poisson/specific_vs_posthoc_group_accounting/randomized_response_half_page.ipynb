{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seml.database as db_utils\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../..')\n",
    "from utils import load_results, merge_guarantees\n",
    "\n",
    "import pickle\n",
    "\n",
    "#from group_amplification.privacy_analysis.utils import get_privacy_spent\n",
    "from warnings import warn\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_privacy_spent(\n",
    "    *, orders: list[float] | float, rdp: list[float] | float, delta: float\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    This code is taken from Opacus, which is available under Apache 2.0 license.\n",
    "    For the camera ready version, we will provide our own implementation\n",
    "    that does not rely on external code.\n",
    "\n",
    "    https://github.com/pytorch/opacus/blob/main/opacus/accountants/analysis/rdp.py\n",
    "    \n",
    "    Computes epsilon given a list of Renyi Differential Privacy (RDP) values at\n",
    "    multiple RDP orders and target ``delta``.\n",
    "    The computation of epslion, i.e. conversion from RDP to (eps, delta)-DP,\n",
    "    is based on the theorem presented in the following work:\n",
    "    Borja Balle et al. \"Hypothesis testing interpretations and Renyi differential privacy.\"\n",
    "    International Conference on Artificial Intelligence and Statistics. PMLR, 2020.\n",
    "    Particullary, Theorem 21 in the arXiv version https://arxiv.org/abs/1905.09982.\n",
    "    Args:\n",
    "        orders: An array (or a scalar) of orders (alphas).\n",
    "        rdp: A list (or a scalar) of RDP guarantees.\n",
    "        delta: The target delta.\n",
    "    Returns:\n",
    "        Pair of epsilon and optimal order alpha.\n",
    "    Raises:\n",
    "        ValueError\n",
    "            If the lengths of ``orders`` and ``rdp`` are not equal.\n",
    "    \"\"\"\n",
    "    orders_vec = np.atleast_1d(orders)\n",
    "    rdp_vec = np.atleast_1d(rdp)\n",
    "\n",
    "    if len(orders_vec) != len(rdp_vec):\n",
    "        raise ValueError(\n",
    "            f\"Input lists must have the same length.\\n\"\n",
    "            f\"\\torders_vec = {orders_vec}\\n\"\n",
    "            f\"\\trdp_vec = {rdp_vec}\\n\"\n",
    "        )\n",
    "\n",
    "    eps = (\n",
    "        rdp_vec\n",
    "        - (np.log(delta) + np.log(orders_vec)) / (orders_vec - 1)\n",
    "        + np.log((orders_vec - 1) / orders_vec)\n",
    "    )\n",
    "\n",
    "    # special case when there is no privacy\n",
    "    if np.isnan(eps).all():\n",
    "        return np.inf, np.nan\n",
    "\n",
    "    idx_opt = np.nanargmin(eps)  # Ignore NaNs\n",
    "    if idx_opt == 0 or idx_opt == len(eps) - 1:\n",
    "        extreme = \"smallest\" if idx_opt == 0 else \"largest\"\n",
    "        warn(\n",
    "            f\"Optimal order is the {extreme} alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\"\n",
    "        )\n",
    "    return eps[idx_opt], orders_vec[idx_opt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'group_amplification_neurips24_rdp'\n",
    "\n",
    "\n",
    "jk_config = {\n",
    "    'username': 'YOURUSERNAME',\n",
    "    'password': 'YOURPASSWORD',\n",
    "    'host': 'YOURDATABASEHOST',\n",
    "    'port': 27017,\n",
    "    'db_name': 'YOURDATABASENAME'\n",
    "}\n",
    "\n",
    "col = db_utils.get_collection(collection, mongodb_config=jk_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiments(col, restrictions={}):\n",
    "    \n",
    "    restrictions['status'] = 'COMPLETED'\n",
    "\n",
    "    if col.count_documents(restrictions) == 0:\n",
    "        raise ValueError('No matches!')\n",
    "\n",
    "    exps = col.find(restrictions, {'config':1, 'result': 1, '_id': 1})\n",
    "    \n",
    "    return exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dp_guarantees(save_file):\n",
    "    with open(save_file, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "\n",
    "    return {\n",
    "        'alphas': np.array(results['alphas']),\n",
    "        'epsilons': np.array(results['epsilons'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exp_result_dict(exp):\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    \n",
    "    result_dict['space'] = exp['config']['alphas']['space']\n",
    "    result_dict['true_response_prob'] = exp['config']['base_mechanism']['params']['true_response_prob']\n",
    "    result_dict['subsampling_rate'] = exp['config']['amplification']['params']['subsampling_rate']\n",
    "\n",
    "    result_dict['group_size'] = exp['config']['amplification']['params']['group_size']\n",
    "    result_dict['insertions'] = exp['config']['amplification']['params']['insertions']\n",
    "\n",
    "    result_dict['tight'] = bool(exp['config']['amplification']['tight'])\n",
    "    result_dict['eval_method'] = exp['config']['amplification']['params']['eval_method']\n",
    "\n",
    "    save_file = exp['result']['save_file']\n",
    "\n",
    "    result_dict['raw_results_file'] = save_file\n",
    "\n",
    "    dp_dict = get_dp_guarantees(result_dict['raw_results_file'])\n",
    "\n",
    "    result_dict.update(dp_dict)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = get_experiments(col, {'config.amplification.subsampling_scheme': 'poisson',\n",
    "                                    'config.base_mechanism.name': 'randomizedresponse',\n",
    "                                    'config.alphas.space': {'$in': ['log', 'log_continuous', 'log_linear']}\n",
    "                                    })\n",
    "results = load_results(\n",
    "            generate_exp_result_dict,\n",
    "            experiments,\n",
    "            results_file='./raw_data_gaussian',\n",
    "            overwrite=False\n",
    "            )\n",
    "\n",
    "results = results.loc[results['eval_method'].isin(['recursive', 'quadrature'])]\n",
    "results = results.loc[results['group_size'].isin([1, 2, 4, 8])]\n",
    "results = results.loc[results['true_response_prob'].isin([0.6])]\n",
    "results = results.loc[results['subsampling_rate'].isin([0.1, 0.001])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_label_map = {\n",
    "        'recursive': 'Post-hoc',\n",
    "        'expansion': 'Specific',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot_dict(data):\n",
    "\n",
    "    plot_dict = {}\n",
    "\n",
    "    for i, (index, row) in enumerate(data.iterrows()):\n",
    "        alphas, epsilons, eval_method, group_size = row.loc[['alphas', 'epsilons', 'eval_method', 'group_size']]\n",
    "\n",
    "        assert eval_method in ['recursive', 'expansion', 'quadrature']\n",
    "\n",
    "        if eval_method == 'recursive':\n",
    "            # Renyi-divergence is non-decreasing --> Make values smaller to favor baseline\n",
    "            epsilons = np.minimum.accumulate(epsilons[::-1])[::-1]\n",
    "        \n",
    "        if eval_method == 'quadrature':\n",
    "            eval_method = 'expansion'\n",
    "\n",
    "        if eval_method not in plot_dict:\n",
    "            plot_dict[eval_method] = {\n",
    "                group_size: (alphas, epsilons),\n",
    "                'label': method_label_map[eval_method]\n",
    "            }\n",
    "        \n",
    "        elif group_size not in plot_dict[eval_method]:\n",
    "\n",
    "            plot_dict[eval_method][group_size] = alphas, epsilons\n",
    "\n",
    "        else:\n",
    "            old_alphas, old_epsilons = plot_dict[eval_method][group_size]\n",
    "            merged_alphas, merged_epsilons = merge_guarantees(old_alphas, alphas,\n",
    "                                                              old_epsilons, epsilons,\n",
    "                                                              max)\n",
    "            \n",
    "            if eval_method == 'recursive':\n",
    "                # Renyi-divergence is non-decreasing --> Make values smaller to favor baseline\n",
    "                merged_epsilons = np.minimum.accumulate(merged_epsilons[::-1])[::-1]\n",
    "\n",
    "            plot_dict[eval_method][group_size] = merged_alphas, merged_epsilons\n",
    "\n",
    "    return plot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_plot_dict(plot_dict, delta: float, iterations: NDArray):\n",
    "    res = plot_dict.copy()\n",
    "\n",
    "    for eval_method, eval_dict in plot_dict.items():\n",
    "        for k in eval_dict:\n",
    "            if isinstance(k, str):\n",
    "                continue\n",
    "            else:\n",
    "                group_size = k\n",
    "            alphas, epsilons = eval_dict[group_size]\n",
    "            delta_epsilons = np.array([get_privacy_spent(orders=alphas, rdp=i * epsilons, delta=delta)[0] for i in iterations])\n",
    "            res[eval_method][group_size] = (iterations, delta_epsilons)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_plot_dict(plot_dict, draw_legend_group_size=False, draw_legend_method=False, width=0.49, xlim=[2, 10000]):\n",
    "    sns.set_theme()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    pal = sns.color_palette('colorblind', 4)[::-1]\n",
    "\n",
    "    smallest_alpha = None\n",
    "    largest_alpha = None\n",
    "\n",
    "    for i, (eval_method, eval_method_dict) in list(enumerate(plot_dict.items())):\n",
    "        group_sizes = np.sort([k for k in eval_method_dict if not isinstance(k, str)])\n",
    "\n",
    "        for j, group_size in enumerate(group_sizes[::-1]):\n",
    "\n",
    "            alphas, epsilons = eval_method_dict[group_size]\n",
    "            smallest_alpha = alphas.min() if smallest_alpha is None else min(smallest_alpha, alphas.min())\n",
    "\n",
    "            prob_label = group_size if eval_method == 'expansion' else None\n",
    "\n",
    "            linestyle = 'solid' if eval_method in ['quadrature', 'expansion'] else 'dashed'\n",
    "\n",
    "            ax.plot(alphas, epsilons, label=prob_label, c=pal[int(np.log2(group_size)) - 1], linestyle=linestyle)\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    ax.tick_params('both', which='major', length=2.5, width=0.75)\n",
    "    ax.tick_params('both', which='minor', length=1.5, width=0.75, left=True)\n",
    "\n",
    "    ax.set_xlabel('Iteration $t$', fontsize=9)\n",
    "    ax.set_ylabel('ADP $\\\\varepsilon$', fontsize=9)\n",
    "\n",
    "    if draw_legend_group_size:\n",
    "        legend_group_size = ax.legend(loc='lower right', title='Group size', title_fontsize=9)\n",
    "\n",
    "    if draw_legend_method:\n",
    "        handles_ls = []\n",
    "        handles_ls.append(ax.plot([], [], c='black', ls='dashed')[0])\n",
    "        handles_ls.append(ax.plot([], [], c='black', ls='solid')[0])\n",
    "\n",
    "        legend_method = ax.legend(handles_ls, list(method_label_map.values()), loc=('upper left' if True else 'lower right'))\n",
    "\n",
    "        if draw_legend_group_size:\n",
    "            ax.add_artist(legend_group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/ceph/hdd/staff/schuchaj/group_amplification_plots/neurips24/rdp/poisson/specific_vs_posthoc_accounting/randomized_response/half_page/both_legends'\n",
    "\n",
    "for x in results.groupby(['subsampling_rate', 'true_response_prob']):\n",
    "\n",
    "    subsampling_rate, true_response_prob = x[0]\n",
    "    plot_dict = prepare_plot_dict(x[1])\n",
    "\n",
    "    print(subsampling_rate, true_response_prob)\n",
    "    plot_dict = convert_plot_dict(plot_dict, 1e-8, np.logspace(0, 5, 121))\n",
    "\n",
    "    draw_legend_method = True\n",
    "    draw_legend_group_size = True\n",
    "\n",
    "    plot_plot_dict(plot_dict, draw_legend_method=draw_legend_method, draw_legend_group_size=draw_legend_group_size, width=0.49, xlim=None)\n",
    "\n",
    "    plt.savefig(f'{save_dir}/{subsampling_rate}_{true_response_prob}.png', dpi=256)\n",
    "\n",
    "    #plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/ceph/hdd/staff/schuchaj/group_amplification_plots/neurips24/rdp/poisson/specific_vs_posthoc_accounting/randomized_response/half_page/no_legend'\n",
    "\n",
    "for x in results.groupby(['subsampling_rate', 'true_response_prob']):\n",
    "\n",
    "    subsampling_rate, true_response_prob = x[0]\n",
    "    plot_dict = prepare_plot_dict(x[1])\n",
    "\n",
    "    print(subsampling_rate, true_response_prob)\n",
    "    plot_dict = convert_plot_dict(plot_dict, 1e-8, np.logspace(0, 5, 121))\n",
    "\n",
    "    draw_legend_method = False\n",
    "    draw_legend_group_size = False\n",
    "\n",
    "    plot_plot_dict(plot_dict, draw_legend_method=draw_legend_method, draw_legend_group_size=draw_legend_group_size, width=0.49, xlim=None)\n",
    "\n",
    "    plt.savefig(f'{save_dir}/{subsampling_rate}_{true_response_prob}.png', dpi=256)\n",
    "\n",
    "    #plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group_amplification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
