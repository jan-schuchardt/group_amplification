{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seml.database as db_utils\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../..')\n",
    "from utils import load_results, merge_guarantees\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'group_amplification_neurips24_rdp'\n",
    "\n",
    "\n",
    "jk_config = {\n",
    "    'username': 'YOURUSERNAME',\n",
    "    'password': 'YOURPASSWORD',\n",
    "    'host': 'YOURDATABASEHOST',\n",
    "    'port': 27017,\n",
    "    'db_name': 'YOURDATABASENAME'\n",
    "}\n",
    "\n",
    "col = db_utils.get_collection(collection, mongodb_config=jk_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiments(col, restrictions={}):\n",
    "    \n",
    "    restrictions['status'] = 'COMPLETED'\n",
    "\n",
    "    if col.count_documents(restrictions) == 0:\n",
    "        raise ValueError('No matches!')\n",
    "\n",
    "    exps = col.find(restrictions, {'config':1, 'result': 1, '_id': 1})\n",
    "    \n",
    "    return exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dp_guarantees(save_file):\n",
    "    with open(save_file, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "\n",
    "    return {\n",
    "        'alphas': np.array(results['alphas']),\n",
    "        'epsilons': np.array(results['epsilons'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exp_result_dict(exp):\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    \n",
    "\n",
    "    result_dict['std'] = exp['config']['base_mechanism']['params']['standard_deviation']\n",
    "    result_dict['dataset_size'] = exp['config']['amplification']['params']['dataset_size']\n",
    "    result_dict['batch_size'] = exp['config']['amplification']['params']['batch_size']\n",
    "\n",
    "    result_dict['group_size'] = exp['config']['amplification']['params']['group_size']\n",
    "\n",
    "    result_dict['tight'] = bool(exp['config']['amplification']['tight'])\n",
    "    result_dict['eval_method'] = exp['config']['amplification']['params']['eval_method']\n",
    "    result_dict['self_consistency'] = bool(exp['config']['amplification']['params']['eval_params'].get('use_self_consistency', False))\n",
    "\n",
    "    save_file = exp['result']['save_file']\n",
    "\n",
    "    result_dict['raw_results_file'] = save_file\n",
    "\n",
    "    dp_dict = get_dp_guarantees(result_dict['raw_results_file'])\n",
    "\n",
    "    result_dict.update(dp_dict)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = get_experiments(col, {'config.amplification.subsampling_scheme': 'withoutreplacement',\n",
    "                                    'config.base_mechanism.name': 'gaussian',\n",
    "                                    'config.alphas.space': 'log'\n",
    "                                    })\n",
    "results = load_results(\n",
    "            generate_exp_result_dict,\n",
    "            experiments,\n",
    "            results_file='./raw_data',\n",
    "            overwrite=False\n",
    "            )\n",
    "\n",
    "results = results.loc[results['eval_method'].isin(['recursive', 'directtransport'])]\n",
    "results = results.loc[results['std'].isin([0.5, 5.0])]\n",
    "results = results.loc[~results['batch_size'].isin([2000, 5000])]\n",
    "\n",
    "\n",
    "results = results.loc[results['group_size'].isin([1, 2, 4])]\n",
    "results = results.loc[results['tight'] | results['self_consistency']]\n",
    "\n",
    "baseline_results_orig = results.loc[~results['tight']].copy()\n",
    "baseline_results = results.loc[~results['tight']]\n",
    "baseline_results['dataset_size'] = baseline_results['dataset_size'].mul(10)\n",
    "baseline_results['batch_size'] = baseline_results['batch_size'].mul(10)\n",
    "results = pd.concat(( baseline_results, results))\n",
    "baseline_results = baseline_results_orig\n",
    "baseline_results['dataset_size'] = baseline_results['dataset_size'].floordiv(10)\n",
    "baseline_results['batch_size'] = baseline_results['batch_size'].floordiv(10)\n",
    "results = pd.concat(( baseline_results, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[(results['dataset_size'] == 1000) & (results['batch_size'] == 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot_dict(data):\n",
    "\n",
    "    method_label_map = {\n",
    "        'recursive': 'Posthoc',\n",
    "        'directtransport': 'No conditioning'\n",
    "    }\n",
    "\n",
    "    plot_dict = {}\n",
    "\n",
    "    for i, (index, row) in enumerate(data.iterrows()):\n",
    "        alphas, epsilons, eval_method, group_size = row.loc[['alphas', 'epsilons', 'eval_method', 'group_size']]\n",
    "\n",
    "        assert eval_method in ['recursive', 'directtransport']\n",
    "\n",
    "        if eval_method == 'recursive':\n",
    "            # Renyi-divergence is non-decreasing --> Make values smaller to favor baseline\n",
    "            epsilons = np.minimum.accumulate(epsilons[::-1])[::-1]\n",
    "\n",
    "        if eval_method not in plot_dict:\n",
    "            plot_dict[eval_method] = {\n",
    "                group_size: (alphas, epsilons),\n",
    "                'label': method_label_map[eval_method]\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            assert group_size not in plot_dict[eval_method]\n",
    "\n",
    "            plot_dict[eval_method][group_size] = alphas, epsilons\n",
    "\n",
    "    return plot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_plot_dict(plot_dict, draw_legend_group_size=False, draw_legend_method=False, width=0.49):\n",
    "    sns.set_theme()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    pal = sns.color_palette('colorblind', 3)\n",
    "\n",
    "    for i, (eval_method, eval_method_dict) in list(enumerate(plot_dict.items()))[::-1]:\n",
    "        group_sizes = np.sort([k for k in eval_method_dict if not isinstance(k, str)])\n",
    "\n",
    "        for j, group_size in enumerate(group_sizes[::-1]):\n",
    "\n",
    "            alphas, epsilons = eval_method_dict[group_size]\n",
    "            \n",
    "            prob_label = group_size if eval_method == 'recursive' else None\n",
    "\n",
    "            linestyle = 'solid' if eval_method == 'recursive' else 'dashed'\n",
    "\n",
    "            ax.plot(alphas, epsilons, label=prob_label, c=pal[j], linestyle=linestyle)\n",
    "\n",
    "\n",
    "    ax.tick_params('both', which='major', length=2.5, width=0.75)\n",
    "    ax.tick_params('both', which='minor', length=1.5, width=0.75, left=False)\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlim(2, 10000)\n",
    "    ax.set_xlabel('RDP $\\\\alpha$', fontsize=9)\n",
    "    ax.set_ylabel('RDP $\\\\rho(\\\\alpha)$', fontsize=9)\n",
    "\n",
    "    if draw_legend_group_size:\n",
    "        legend_group_size = ax.legend(loc='lower right', title='Group size', title_fontsize=9)\n",
    "\n",
    "    if draw_legend_method:\n",
    "        handles_ls = []\n",
    "        handles_ls.append(ax.plot([], [], c='black', ls='dashed')[0])\n",
    "        handles_ls.append(ax.plot([], [], c='black', ls='solid')[0])\n",
    "        legend_method = ax.legend(handles_ls, ['No conditioning', 'Post-hoc'], loc=('upper left' if draw_legend_group_size else 'lower right'))\n",
    "\n",
    "        if draw_legend_group_size:\n",
    "            ax.add_artist(legend_group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/ceph/hdd/staff/schuchaj/group_amplification_plots/neurips24/rdp/without_replacement/direct_transport_vs_posthoc/gaussian/half_page/both_legends'\n",
    "\n",
    "for x in results.groupby(['dataset_size', 'batch_size', 'std']):\n",
    "\n",
    "    dataset_size, batch_size, std = x[0]\n",
    "    plot_dict = prepare_plot_dict(x[1])\n",
    "\n",
    "    plot_plot_dict(plot_dict, draw_legend_group_size=True, draw_legend_method=True, width=0.49)\n",
    "    \n",
    "    plt.savefig(f'{save_dir}/{dataset_size}_{batch_size}_{std}.png', dpi=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/ceph/hdd/staff/schuchaj/group_amplification_plots/neurips24/rdp/without_replacement/direct_transport_vs_posthoc/gaussian/half_page/no_legend'\n",
    "\n",
    "for x in results.groupby(['dataset_size', 'batch_size', 'std']):\n",
    "\n",
    "    dataset_size, batch_size, std = x[0]\n",
    "    plot_dict = prepare_plot_dict(x[1])\n",
    "\n",
    "    plot_plot_dict(plot_dict, draw_legend_group_size=False, draw_legend_method=False, width=0.49)\n",
    "    \n",
    "    plt.savefig(f'{save_dir}/{dataset_size}_{batch_size}_{std}.png', dpi=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d24e68175ae8eeb8c8f134fc7c9864756013aed1eb751f543be6d886f03d4571"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('invariance_smoothing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
