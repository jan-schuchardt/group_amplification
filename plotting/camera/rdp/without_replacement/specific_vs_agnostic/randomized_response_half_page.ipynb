{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seml.database as db_utils\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../..')\n",
    "from utils import load_results, merge_guarantees\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'group_amplification_neurips24_rdp'\n",
    "\n",
    "\n",
    "jk_config = {\n",
    "    'username': 'YOURUSERNAME',\n",
    "    'password': 'YOURPASSWORD',\n",
    "    'host': 'YOURDATABASEHOST',\n",
    "    'port': 27017,\n",
    "    'db_name': 'YOURDATABASENAME'\n",
    "}\n",
    "\n",
    "col = db_utils.get_collection(collection, mongodb_config=jk_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiments(col, restrictions={}):\n",
    "    \n",
    "    restrictions['status'] = 'COMPLETED'\n",
    "\n",
    "    if col.count_documents(restrictions) == 0:\n",
    "        raise ValueError('No matches!')\n",
    "\n",
    "    exps = col.find(restrictions, {'config':1, 'result': 1, '_id': 1})\n",
    "    \n",
    "    return exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dp_guarantees(save_file):\n",
    "    with open(save_file, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "\n",
    "    return {\n",
    "        'alphas': np.array(results['alphas']),\n",
    "        'epsilons': np.array(results['epsilons'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exp_result_dict(exp):\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    \n",
    "\n",
    "    result_dict['true_response_prob'] = exp['config']['base_mechanism']['params']['true_response_prob']\n",
    "    result_dict['dataset_size'] = exp['config']['amplification']['params']['dataset_size']\n",
    "    result_dict['batch_size'] = exp['config']['amplification']['params']['batch_size']\n",
    "\n",
    "    result_dict['group_size'] = exp['config']['amplification']['params']['group_size']\n",
    "\n",
    "    result_dict['tight'] = bool(exp['config']['amplification']['tight'])\n",
    "    result_dict['eval_method'] = exp['config']['amplification']['params']['eval_method']\n",
    "    result_dict['self_consistency'] = bool(exp['config']['amplification']['params']['eval_params'].get('use_self_consistency', False))\n",
    "\n",
    "    save_file = exp['result']['save_file']\n",
    "\n",
    "    result_dict['raw_results_file'] = save_file\n",
    "\n",
    "    dp_dict = get_dp_guarantees(result_dict['raw_results_file'])\n",
    "\n",
    "    result_dict.update(dp_dict)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = get_experiments(col, {'config.amplification.subsampling_scheme': 'withoutreplacement',\n",
    "                                    'config.base_mechanism.name': 'randomizedresponse',\n",
    "                                    'config.alphas.space': {'$in': ['log']},\n",
    "                                    'config.amplification.params.group_size': 1,\n",
    "                                    'config.amplification.params.dataset_size': 10000\n",
    "                                    })\n",
    "results = load_results(\n",
    "            generate_exp_result_dict,\n",
    "            experiments,\n",
    "            results_file='./raw_data_randomized_response',\n",
    "            overwrite=False\n",
    "            )\n",
    "\n",
    "results = results.loc[~(results['self_consistency'])]\n",
    "results = results.loc[results['eval_method'].isin(['recursive', 'quadrature'])]\n",
    "results = results.loc[results['true_response_prob'].isin([0.6, 0.75, 0.9])]\n",
    "\n",
    "\n",
    "#results = results.loc[results['eval_method'].isin(['recursive', 'expansion', 'quadrature'])]\n",
    "#\n",
    "#results = results.loc[results['group_size'].isin([2, 4, 8])]\n",
    "#results = results.loc[results['subsampling_rate'].isin([0.2, 0.1, 0.001])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot_dict(dataset_size, batch_size, data):\n",
    "\n",
    "    method_label_map = {\n",
    "        'recursive': 'Agnostic',\n",
    "        'quadrature': 'Specific'\n",
    "    }\n",
    "\n",
    "    plot_dict = {}\n",
    "\n",
    "    for i, (index, row) in enumerate(data.iterrows()):\n",
    "        alphas, epsilons, eval_method, true_response_prob = row.loc[['alphas', 'epsilons', 'eval_method', 'true_response_prob']]\n",
    "\n",
    "        assert eval_method in ['recursive', 'quadrature']\n",
    "\n",
    "        if eval_method == 'recursive':\n",
    "            # Renyi-divergence is non-decreasing --> Make values smaller to favor baseline\n",
    "            epsilons = np.minimum.accumulate(epsilons[::-1])[::-1]\n",
    "\n",
    "        if eval_method not in plot_dict:\n",
    "            plot_dict[eval_method] = {\n",
    "                true_response_prob: (alphas, epsilons),\n",
    "                'label': method_label_map[eval_method]\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            assert true_response_prob not in plot_dict[eval_method]\n",
    "\n",
    "            plot_dict[eval_method][true_response_prob] = alphas, epsilons\n",
    "\n",
    "    return plot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_plot_dict(plot_dict, draw_legend_method=False, draw_legend_probs=False, width=0.49):\n",
    "    sns.set_theme()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    pal = sns.color_palette('colorblind', 3)\n",
    "\n",
    "    for i, (eval_method, eval_method_dict) in list(enumerate(plot_dict.items()))[::-1]:\n",
    "        true_response_probs = np.sort([k for k in eval_method_dict if not isinstance(k, str)])\n",
    "\n",
    "        for j, true_response_prob in enumerate(true_response_probs[::-1]):\n",
    "\n",
    "            alphas, epsilons = eval_method_dict[true_response_prob]\n",
    "            \n",
    "            prob_label = true_response_prob if eval_method == 'quadrature' else None\n",
    "\n",
    "            linestyle = 'solid' if eval_method == 'quadrature' else 'dashed'\n",
    "\n",
    "            ax.plot(alphas, epsilons, label=prob_label, c=pal[j], linestyle=linestyle)\n",
    "\n",
    "\n",
    "    ax.tick_params('both', which='major', length=2.5, width=0.75)\n",
    "    ax.tick_params('both', which='minor', length=1.5, width=0.75, left=False)\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlim(2, 10000)\n",
    "    ax.set_xlabel('RDP $\\\\alpha$', fontsize=9)\n",
    "    ax.set_ylabel('RDP $\\\\rho(\\\\alpha)$', fontsize=9)\n",
    "\n",
    "    if draw_legend_probs:\n",
    "        legend_probs = ax.legend(loc='lower right', title='$\\\\theta$', title_fontsize=9)\n",
    "\n",
    "    if draw_legend_method:\n",
    "        handles_ls = []\n",
    "        handles_ls.append(ax.plot([], [], c='black', ls='dashed')[0])\n",
    "        handles_ls.append(ax.plot([], [], c='black', ls='solid')[0])\n",
    "        legend_method = ax.legend(handles_ls, [v['label'] for v in list(plot_dict.values())], loc=('upper left' if draw_legend_probs else 'lower right'))\n",
    "\n",
    "        if draw_legend_probs:\n",
    "            ax.add_artist(legend_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/ceph/hdd/staff/schuchaj/group_amplification_plots/neurips24/rdp/without_replacement/specific_vs_agnostic/randomized_response/half_page'\n",
    "\n",
    "for x in results.groupby(['dataset_size', 'batch_size']):\n",
    "\n",
    "    dataset_size, batch_size = x[0]\n",
    "    plot_dict = prepare_plot_dict(dataset_size, batch_size, x[1])\n",
    "    plot_plot_dict(plot_dict, draw_legend_method=(batch_size in [10, 100]), draw_legend_probs=(batch_size in [10, 100]))\n",
    "    \n",
    "    plt.savefig(f'{save_dir}/{dataset_size}_{batch_size}.png', dpi=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d24e68175ae8eeb8c8f134fc7c9864756013aed1eb751f543be6d886f03d4571"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('invariance_smoothing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
